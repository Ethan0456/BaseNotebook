# -*- coding: utf-8 -*-
"""Base-Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/136IqQkVQkBHFlHmB8XwyohWjFKMECcW0
"""

import importlib.util
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import *
from sklearn.linear_model import *
import pickle
import joblib
from joblib import Parallel, delayed

sns.set()
sns.set_palette('bright')

libraries = ['catboost', 'optuna','scikit-lego', 'pickle', 'joblib','xgboost','Boruta']
gdrive_path = "/content/drive/MyDrive/Datasets/"



####################################################################
### Installing and Importing Libraries

def install_libraries(libraries):
    print('*'*50)
    print('IMPORTING LIBRARIES')
    for library in libraries:
        print('-'*50)
        spec = importlib.util.find_spec(library)
        if (spec is not None):
            print(f'{library} : ALREADY EXISTS')
            pass
        else:
            os.system(f'pip3 install {library}')
            print(f'{library} : INSTALLED')
    print('*'*50)


####################################################################
### Quantile Capping

def quantile_capping(data):
    # Set the lower and upper quantile ranges
    lower_quantile = 0.05
    upper_quantile = 0.95

    # Perform quantile capping
    data_capped = data.clip(lower=data.quantile(lower_quantile), upper=data.quantile(upper_quantile), axis=1)

    print("-"*50)
    print(data.quantile(lower_quantile))
    print(data.quantile(upper_quantile))
    print("-"*50)

#     print(data_capped)
    return data_capped

####################################################################
### Custom Histplot

def histplot(data, cols, nrows, ncols, hue=None, fsx=10, fsy=10):
    fig, ax = plt.subplots(nrows, ncols, figsize=(fsx, fsy))
    for var, subplot in zip(cols, ax.flatten()):
        sns.histplot(data=data, x=var, ax=subplot, hue=hue)

####################################################################
### Custom Jointplot

from itertools import product

def jointplot(data, x_col, y_col, kind, nrows, ncols, hue=None, fsx=10, fsy=10):
    # fig, ax = plt.subplots(nrows, ncols, figsize=(fsx, fsy))
    combinations = list(product(x_col, y_col))

    for var, subplot in zip(combinations, ax.flatten()):
        sns.jointplot(data=data, x=var[0], y=var[1],  hue=hue, kind=kind)

####################################################################
### Custom Countplot

def countplot(data, x_col, nrows, ncols, hue=None, fsx=10, fsy=10):
    fig, ax = plt.subplots(nrows, ncols, figsize=(fsx, fsy))

    for var, subplot in zip(x_col, ax.flatten()):
        sns.countplot(data=data, x=var, hue=hue, ax=subplot)

####################################################################
### Custom Kdeplot

def kdeplot(data, cols, nrows, ncols, hue=None, fsx=10, fsy=10):
    fig, ax = plt.subplots(nrows, ncols, figsize=(fsx, fsy))
    for var, subplot in zip(cols, ax.flatten()):
        sns.kdeplot(data=data, x=var, ax=subplot, hue=hue, fill=True)

####################################################################
### RandomForest Imputation

def random_forest_regressor_imputation(X_train, y_train, X_test):
    # Scale the features for better performance
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train a RandomForestRegressor to predict the missing target values
    regressor = RandomForestRegressor()
    regressor.fit(X_train_scaled, y_train)
    # Predict the missing target values
    imputed_values = regressor.predict(X_test_scaled)

    return imputed_values

####################################################################
### Custom Boxplot

def boxplot(data, cols, nrows, ncols, hue=None, fsx=10, fsy=10):
    fig, ax = plt.subplots(nrows, ncols, figsize=(fsx, fsy))
    for var, subplot in zip(cols, ax.flatten()):
        sns.boxplot(data=data, x=var, ax=subplot, hue=hue)

####################################################################
### Import Google Drive

def import_gdrive():
    from google.colab import drive
    try:
        drive.mount('/content/drive')
    except:
        print("Credential propagation was unsuccessful")

####################################################################
### Export Model

def export_model(model, model_name,method='pickle'):
    if (method == 'pickle'):
        saved_model = pickle.dumps(model)
    elif (method == 'joblib'):
        joblib.dump(model, f'{model_name}.pkl')
    else:
        print('Give Proper Parameter for "method"')
    print(f'{model_name} Model Export Successful')

####################################################################
### Import Model

def import_model(model_path, method='pickle'):
    if (method == 'pickle'):
        model = pickle.loads(model_path)
        return model
    elif (method == 'joblib'):
        model = joblib.load(model_path)
        return model
    else:
        print('Give Proper Parameter for "method"')

####################################################################